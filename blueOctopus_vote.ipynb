{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9wvaJiNpOHMn"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import statistics\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install uci-dataset\n",
        "from sklearn import datasets\n",
        "import uci_dataset as dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o99rL4FFpYJm",
        "outputId": "d8819597-1c84-4a85-b3f8-c554b4268c0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting uci-dataset\n",
            "  Downloading uci_dataset-0.0.7-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: xlrd>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from uci-dataset) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.8/dist-packages (from uci-dataset) (1.0.2)\n",
            "Collecting rarfile\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from uci-dataset) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from uci-dataset) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.13 in /usr/local/lib/python3.8/dist-packages (from uci-dataset) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.13->uci-dataset) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.13->uci-dataset) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.13->uci-dataset) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.0->uci-dataset) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.0->uci-dataset) (3.1.0)\n",
            "Installing collected packages: rarfile, uci-dataset\n",
            "Successfully installed rarfile-4.0 uci-dataset-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion(y_test, y_pred):\n",
        "  mat = confusion_matrix(y_test, y_pred)\n",
        "  plt.subplots(figsize=(12,8))\n",
        "  sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
        "  plt.xlabel('true label')\n",
        "  plt.ylabel('predicted label')\n"
      ],
      "metadata": {
        "id": "lpY0VjaNtGf-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jm-Pu6CX_DDu"
      },
      "outputs": [],
      "source": [
        "#1 Normal KNN\n",
        "def normalKNN(trainX, testX, trainY, testY):\n",
        "  model = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree')\n",
        "  model.fit(trainX, trainY)\n",
        "  predicted = model.predict(testX)\n",
        "  print(\"Accuracy Score = \", metrics.accuracy_score(testY, predicted))\n",
        "  return predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QAzlT5uZ06f"
      },
      "source": [
        "Leave-one-out cross validation is K-fold cross validation taken to its logical extreme, with K equal to N, the number of data points in the set. That means that N separate times, the function approximator is trained on all the data except for one point and a prediction is made for that point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LwU3mquaATQx"
      },
      "outputs": [],
      "source": [
        "#2 Local Unrestricted KNN\n",
        "def getValidk(trainX,trainY):\n",
        "  loo = LeaveOneOut()\n",
        "  loo.get_n_splits(trainX)\n",
        "  validK = []\n",
        "  for train_index, test_index in loo.split(trainX):\n",
        "    trainData, testData = trainX[train_index], trainX[test_index]\n",
        "    trainLabel, testLabel = trainY[train_index], trainY[test_index]\n",
        "    validSampleK = []\n",
        "    for k in range(2, 30):\n",
        "        model = KNeighborsClassifier(n_neighbors=k)\n",
        "        model.fit(trainData, trainLabel)\n",
        "        predicted = model.predict(testData)\n",
        "        if predicted == testLabel:   \n",
        "            validSampleK.append(k)\n",
        "    validK.append(validSampleK)\n",
        "  validK = np.array(validK)\n",
        "  return validK\n",
        "\n",
        "def getPreTrainedModels(trainX, trainY):\n",
        "  trainedModels = []\n",
        "  for i in range(2, 30):\n",
        "    model = KNeighborsClassifier(n_neighbors=i, algorithm='ball_tree')\n",
        "    model.fit(trainX, trainY)\n",
        "    trainedModels.append(model)\n",
        "  return trainedModels    \n",
        "\n",
        "def getPrediction(validK, trainedModels, M, trainX, testX, trainY):\n",
        "  finalPredictions = []\n",
        "  unique_k = set()\n",
        "  for i in range(0, len(testX)):\n",
        "    distances = []\n",
        "    for j in range(0, len(trainX)):\n",
        "        distances.append(np.linalg.norm(testX[i] - trainX[j]))\n",
        "    distances = np.array(distances)\n",
        "    indices = np.argsort(distances)\n",
        "    nebrIndices = indices[0:M]\n",
        "    nebrLabels = trainY[nebrIndices]\n",
        "\n",
        "    kCorrectClassified = np.zeros(30)\n",
        "    for ind in indices:\n",
        "        kcurrArray = validK[ind]\n",
        "        for z in range(len(kcurrArray)):\n",
        "            k = kcurrArray[z]\n",
        "            kCorrectClassified[k] += 1\n",
        "    kbest = np.argmax(kCorrectClassified)\n",
        "    unique_k.add(kbest)\n",
        "    predictedClass = trainedModels[kbest - 2].predict(testX[i].reshape(1, -1))\n",
        "    finalPredictions.append(predictedClass)\n",
        "  return finalPredictions,unique_k\n",
        "\n",
        "def localUnrestrictedKNN(trainX, testX, trainY, testY, M):\n",
        "  validK = getValidk(trainX,trainY)\n",
        "  trainedModels = getPreTrainedModels(trainX, trainY)\n",
        "  predicted ,uniquek = getPrediction(validK, trainedModels, M, trainX, testX, trainY)\n",
        "  print(\"mean k values = \",statistics.mean(uniquek) )\n",
        "  print(\"Accuracy Score = \", metrics.accuracy_score(testY, predicted)) \n",
        "  return predicted,uniquek"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Pruned KNN\n",
        "\n",
        "def prunedKNN(trainX, testX, trainY, testY, M):\n",
        "  validK = getValidk(trainX,trainY)\n",
        "  finalK = []\n",
        "  for lst in validK:\n",
        "    finalK = finalK + lst\n",
        "  freq = np.bincount(np.array(finalK))\n",
        "  print(freq, finalK)\n",
        "  plt.plot(freq)\n",
        "\n",
        "  L = 114\n",
        "  array_list = []\n",
        "  for m in range(len(validK)):\n",
        "    array_list.append(np.array(validK[m]))\n",
        "\n",
        "  validK = array_list\n",
        "  arr = np.array(validK)\n",
        "  freq_to_prune = []\n",
        "\n",
        "  for i in range(len(freq)):\n",
        "    if(freq[i] < L):\n",
        "      freq_to_prune.append(i)\n",
        "\n",
        "  for i in range(arr.shape[0]):\n",
        "      for j in freq_to_prune:\n",
        "        if j in arr[i] and arr[i].shape[0] != 1:\n",
        "          arr[i] = np.delete(arr[i], np.where(arr[i] == j))\n",
        "  print(arr)"
      ],
      "metadata": {
        "id": "IMtwfwzfl93G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 KNN One Per Class\n",
        "def k_one_per_class(trainX,trainY):\n",
        "  loo = LeaveOneOut()\n",
        "  loo.get_n_splits(trainX)\n",
        "  unique_class = np.unique(trainY)\n",
        "  k_for_each_class = {}\n",
        "  for i in unique_class:\n",
        "    k_for_each_class[i] = [0 for i in range(2,30)]\n",
        "  for train_index, test_index in loo.split(trainX):\n",
        "    trainData, testData = trainX[train_index], trainX[test_index]\n",
        "    trainLabel, testLabel = trainY[train_index], trainY[test_index]\n",
        "    for k in range(2, 30):\n",
        "        model = KNeighborsClassifier(n_neighbors=k)\n",
        "        model.fit(trainData, trainLabel)\n",
        "        predicted = model.predict(testData)\n",
        "        if predicted == testLabel:\n",
        "          k_for_each_class[testLabel[0]][k-2] += 1\n",
        "        \n",
        "  k_assigned_for_each_class = {}\n",
        "  for i in unique_class:\n",
        "    k_assigned_for_each_class[i] = np.argmax(k_for_each_class[i])+2\n",
        "  return k_assigned_for_each_class\n",
        "\n",
        "def localKNNoneperclass(trainX, testX, trainY, testY):\n",
        "  unique_k =set()\n",
        "  k_assigned_for_each_class = k_one_per_class(trainX,trainY)\n",
        "  predicted = []\n",
        "  for i in range(0, len(testX)):\n",
        "    distances = []\n",
        "    for j in range(0, len(trainX)):\n",
        "        distances.append(np.linalg.norm(testX[i] - trainX[j]))\n",
        "    distances = np.array(distances)\n",
        "    indices = np.argsort(distances)\n",
        "    percent_of_classification_as_class = {}\n",
        "    for x in k_assigned_for_each_class:\n",
        "      k = k_assigned_for_each_class[x]\n",
        "      unique_k.add(k)\n",
        "      nebrIndices = indices[0:k]\n",
        "      nebrLabels = trainY[nebrIndices]\n",
        "      percent_of_classification_as_class[x] = np.count_nonzero(nebrLabels == x)/k\n",
        "    predicted.append(max(percent_of_classification_as_class, key=percent_of_classification_as_class.get))\n",
        "  print(\"mean k values = \",statistics.mean(unique_k) )\n",
        "  print(\"Accuracy Score = \", metrics.accuracy_score(testY, predicted))\n",
        "  return predicted,unique_k\n",
        " "
      ],
      "metadata": {
        "id": "K2Q-t2_Vl_ZQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 KNN One Per Cluster\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def getK(trainX):\n",
        "  model = KMeans()\n",
        "  visualizer = KElbowVisualizer(model, k=(2,100), metric='silhouette', timings=False)\n",
        "  visualizer.fit(trainX)        # Fit the data to the visualizer\n",
        "  visualizer.show()        # Finalize and render the figure\n",
        "  kAtElbow = visualizer.elbow_value_\n",
        "  return kAtElbow\n",
        "\n",
        "\n",
        "\n",
        "def k_one_per_cluster(trainX, trainY, testX, testY):\n",
        "    \n",
        "    # bestK = getK(trainX)\n",
        "    bestK = 9\n",
        "    kmeans = KMeans(n_clusters=bestK, random_state=0).fit(trainX)\n",
        "    labels = kmeans.labels_\n",
        "    k_for_each_cluster = {}\n",
        "    for i in np.unique(labels):\n",
        "      k_for_each_cluster[i] = [0 for i in range(2,30)]\n",
        "    \n",
        "    validK = getValidk(trainX, trainY) \n",
        "    for i in range(len(validK)):\n",
        "      #print(validK[i],labels[i]) \n",
        "      for j in range(len(validK[i])):\n",
        "        k_for_each_cluster[labels[i]][validK[i][j]-2] += 1\n",
        "    k_assigned_for_each_cluster = {}\n",
        "    for i in np.unique(labels):\n",
        "      k_assigned_for_each_cluster[i] = np.argmax(k_for_each_cluster[i])+2\n",
        "    return k_assigned_for_each_cluster, labels , kmeans\n",
        "\n",
        "def localKNNonepercluster(trainX,testX, trainY, testY):\n",
        "  uniquek = set()\n",
        "  models = getPreTrainedModels(trainX, trainY)\n",
        "  k_assigned_for_each_cluster, labels ,kmeans = k_one_per_cluster(trainX, trainY, testX, testY)\n",
        "  predicted = []\n",
        "  for i in range(0, len(testX)):\n",
        "    cluster_predicted = kmeans.predict(testX[i].reshape(1, -1))\n",
        "\n",
        "    #print(k_assigned_for_each_cluster)\n",
        "    bestk = k_assigned_for_each_cluster[cluster_predicted[0]]\n",
        "    uniquek.add(bestk)\n",
        "    model = models[bestk-2]\n",
        "    predicted.append(model.predict(testX[i].reshape(1, -1)))\n",
        "  print(\"mean k values = \",statistics.mean(uniquek) )\n",
        "  print(\"Accuracy Score = \", metrics.accuracy_score(testY, predicted))\n",
        "  return predicted,uniquek\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nxdbf1SERRY8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\n",
        "# load the dataset\n",
        "def load_dataset(full_path):\n",
        "\t# load the dataset as a numpy array\n",
        "\tdata = pd.read_csv(full_path, header=None)\n",
        "\t# retrieve numpy array\n",
        "\tdata = data.values\n",
        "\t# split into input and output elements\n",
        "\tX, y = data[:, :-1], data[:, -1]\n",
        "\t# label encode the target variable to have the classes 0 and 1\n",
        "\ty = preprocessing.LabelEncoder().fit_transform(y)\n",
        "\treturn X, y\n",
        "# load the dataset\n",
        "def load_dataset(full_path):\n",
        "\t# load the dataset as a numpy array\n",
        "  data = pd.read_csv(full_path, header=None)\n",
        "  print(data.head())\n",
        "  data = data.values\n",
        "\t# split into input and output elements\n",
        "  X, y = data[:, :-1], data[:, -1]\n",
        "\t# label encode the target variable to have the classes 0 and 1\n",
        "  y = preprocessing.LabelEncoder().fit_transform(y)\n",
        "  return X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXhC8QdifKcp",
        "outputId": "185125cd-a5b5-4686-b7ea-8ea9ecc18bae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-01 13:59:36--  https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18171 (18K) [application/x-httpd-php]\n",
            "Saving to: ‘house-votes-84.data’\n",
            "\n",
            "house-votes-84.data 100%[===================>]  17.75K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-12-01 13:59:36 (277 KB/s) - ‘house-votes-84.data’ saved [18171/18171]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nVo5GWOwCrgL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "c5012322-fc2d-4077-da94-c5ca07347e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           0  1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16\n",
            "0  republican  n  y  n  y  y  y  n  n  n  y  ?  y  y  y  n  y\n",
            "1  republican  n  y  n  y  y  y  n  n  n  n  n  y  y  y  n  ?\n",
            "2    democrat  ?  y  y  ?  y  y  n  n  n  n  y  n  y  y  n  n\n",
            "3    democrat  n  y  y  n  ?  y  n  n  n  n  y  n  y  n  n  y\n",
            "4    democrat  y  y  y  n  y  y  n  n  n  n  y  ?  y  y  y  y\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1b3e48dc0132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mnormalized_x_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mnormalized_x_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1790\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'%d' is not a supported axis\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1793\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'republican'"
          ]
        }
      ],
      "source": [
        "def get_dataset(dataset):\n",
        "  X = dataset.data\n",
        "  y = dataset.target\n",
        "  return X, y\n",
        "\n",
        "# iris\n",
        "#X, y = get_dataset(datasets.load_iris())\n",
        "\n",
        "# glass\n",
        "X,y = load_dataset(\"house-votes-84.data\")\n",
        "# wine\n",
        "# X, y = get_dataset(datasets.load_wine())\n",
        "\n",
        "\n",
        "\n",
        "#X, y = get_dataset(dataset.load)\n",
        "trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "normalized_x_train = normalize(trainX)\n",
        "normalized_x_test = normalize(testX)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(27, 9))\n",
        "\n",
        "def plot_data(trainX, trainy):\n",
        "    x = trainX.reshape(trainX.shape[0], -1)\n",
        "    tsne = TSNE(n_components=2, random_state=1, learning_rate=\"auto\",init=\"pca\")\n",
        "    z = tsne.fit_transform(x)\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df[\"y\"] = trainy\n",
        "    df[\"component-1\"] = z[:, 0]\n",
        "    df[\"component-2\"] = z[:, 1]\n",
        "    print(len(np.unique(trainy)))\n",
        "    sns.scatterplot(\n",
        "        x=\"component-1\",\n",
        "        y=\"component-2\",\n",
        "        hue=df.y.tolist(),\n",
        "        palette=sns.color_palette(\"hls\", len(np.unique(trainy))),\n",
        "        data=df,\n",
        "    ).set(title=\"Data T-SNE projection\")\n",
        "\n",
        "\n",
        "for i in range(1,11):\n",
        "    knn=KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(normalized_x_train,trainY)\n",
        "    ax = figure.add_subplot(2,5, i)\n",
        "    pred_i = knn.predict(normalized_x_test)\n",
        "    plot_data(normalized_x_test, pred_i)"
      ],
      "metadata": {
        "id": "ikWmhyZdkaNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_rate=[]\n",
        "for i in range(1,40):\n",
        "    knn=KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(normalized_x_train,trainY)\n",
        "    pred_i = knn.predict(normalized_x_test)\n",
        "    error_rate.append(np.mean(pred_i != testY))\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='red', markersize=10)\n",
        "plt.title('Error Rate vs. K Value')\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Error Rate');\n"
      ],
      "metadata": {
        "id": "vGnBj-2zlRRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRoLGotaUJwU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = normalKNN(normalized_x_train, normalized_x_test, trainY, testY)"
      ],
      "metadata": {
        "id": "E4jso9GXk7K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion( testY,predicted)"
      ],
      "metadata": {
        "id": "VaxE07F1swWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted,uniqueks = localUnrestrictedKNN(normalized_x_train, normalized_x_test, trainY, testY, 2)"
      ],
      "metadata": {
        "id": "TYfZoPuMk7aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion( testY,predicted)"
      ],
      "metadata": {
        "id": "mefkpuqbsxzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted,uniqueks = localKNNoneperclass(normalized_x_train, normalized_x_test, trainY, testY)"
      ],
      "metadata": {
        "id": "XoD4pYyOk979"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion( testY,predicted)"
      ],
      "metadata": {
        "id": "dVP1Ec9js1mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = prunedKNN(normalized_x_train, normalized_x_test, trainY, testY, 2)"
      ],
      "metadata": {
        "id": "lSBeg1PRmvlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion( testY,predicted)"
      ],
      "metadata": {
        "id": "o1RbInz5FGBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted,uniqueks = localKNNonepercluster(normalized_x_train, normalized_x_test, trainY, testY)"
      ],
      "metadata": {
        "id": "gjSGpyqgRjGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion( testY,predicted)"
      ],
      "metadata": {
        "id": "mkDUiixwsgtF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}